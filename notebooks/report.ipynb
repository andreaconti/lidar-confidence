{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "charitable-rainbow",
   "metadata": {},
   "source": [
    "# Results report\n",
    "\n",
    "This notebook summarizes the results obtained from the current model versus the baseline providing quantitative and qualitative results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f9425f-9df7-463e-a85b-60884b5a1eb7",
   "metadata": {},
   "source": [
    "## Comparison with the baseline [Uncertainty-Aware CNNs for Depth Completion: Uncertainty from Beginning to End](https://arxiv.org/abs/2006.03349)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mechanical-minister",
   "metadata": {},
   "source": [
    "### Area Under the Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relevant-kruger",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from lidar_confidence.metrics import percentiles\n",
    "from lidar_confidence.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import functional as F\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from tabulate import tabulate\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(str(Path(\"../experiments/baselines/ncnn/models\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-gibson",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path(\"../results/lce/lce.json\"), \"rt\") as f:\n",
    "    model_results = json.load(f)\n",
    "\n",
    "ncnn_baselines_names = [\n",
    "    \"ncnn_conf_l1\",\n",
    "    \"ncnn_conf_l1_kitti_limited\",\n",
    "    \"ncnn_conf_l2\",\n",
    "    \"ncnn_conf_l2_kitti_limited\",\n",
    "    \"pncnn_exp\",\n",
    "    \"pncnn_exp_kitti_limited\",\n",
    "    \"pncnn\",\n",
    "    \"pncnn_kitti_limited\",\n",
    "]\n",
    "    \n",
    "ncnn_baselines = {}\n",
    "for file_path in [f\"../results/baselines/{name}.json\" for name in ncnn_baselines_names]:\n",
    "    with open(Path(file_path), \"rt\") as f:\n",
    "        name = Path(file_path).name.split(\".\")[0]\n",
    "        ncnn_baselines[name] = json.load(f)   \n",
    "\n",
    "headers = [\"name\", \"test_1/auc_mae\", \"test_1/auc_rmse\", \"test_2/auc_mae\", \"test_2/auc_rmse\"]\n",
    "lines = []\n",
    "lines.append([\"ours\", *[model_results[f] for f in headers[1:]]])\n",
    "for name in ncnn_baselines:\n",
    "    lines.append([name, *[ncnn_baselines[name][f] for f in headers[1:]]])\n",
    "\n",
    "print(\"AUC METRICS\\n\")\n",
    "print(tabulate(lines, headers=headers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imported-endorsement",
   "metadata": {},
   "source": [
    "### RMSE removing the less confident measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-audio",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transform(d):\n",
    "    for k in d:\n",
    "        d[k] = F.to_tensor(d[k])\n",
    "    d[\"img\"] = F.normalize(d[\"img\"], mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    return d\n",
    "\n",
    "ds_split_142 = Dataset(\"../data/dataset\", transform=transform, split=\"test_2\")\n",
    "dl_split_142 = DataLoader(ds_split_142)\n",
    "\n",
    "model = torch.jit.load(\"../results/lce/model.pth\").to(\"cuda\")\n",
    "\n",
    "baselines = {}\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    for baseline_name in ncnn_baselines_names:\n",
    "        sys.path.append(str(Path(f\"../experiments/baselines/ncnn/models/{baseline_name}\")))\n",
    "        baselines[baseline_name] = (\n",
    "            torch.load(f\"../experiments/baselines/ncnn/models/{baseline_name}/model.pth\", map_location=\"cuda\")[\"model\"]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overall-share",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [100, 95, 90, 80, 70, 60, 50, 40, 30, 20]\n",
    "\n",
    "def compute_error(lidar, gt, conf_mask, depth_mask=None):\n",
    "    \n",
    "    if depth_mask is None:\n",
    "        mask = (lidar > 0) & (gt > 0)\n",
    "    else:\n",
    "        mask = depth_mask\n",
    "        \n",
    "    lidar_, gt_ = lidar[mask][conf_mask], gt[mask][conf_mask]\n",
    "    err = torch.sqrt(torch.mean(torch.square(lidar_ - gt_)))\n",
    "    return err\n",
    "\n",
    "errs = defaultdict(lambda: [])\n",
    "for batch in tqdm(dl_split_142):\n",
    "    mask = (batch[\"lidar\"] > 0) & (batch[\"gt\"] > 0)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        std = model(torch.cat([batch[\"img\"].to(\"cuda\"), batch[\"lidar\"].to(\"cuda\")], 1)).cpu()[mask]\n",
    "        \n",
    "        base_confs = {}\n",
    "        for name, base_model in baselines.items():\n",
    "            base_confs[name] = base_model(batch[\"lidar\"].to(\"cuda\"))[:, 2:].cpu()[mask]\n",
    "        \n",
    "    mine_err = []\n",
    "    for perc in thresholds:\n",
    "        percentile = percentiles(std, [perc])[0, 0]\n",
    "        mine_err.append(compute_error(batch[\"lidar\"], batch[\"gt\"], std <= percentile))\n",
    "    errs[\"our\"].append(mine_err)\n",
    "    \n",
    "    for name in baselines:\n",
    "        base_err = []\n",
    "        for perc in thresholds:\n",
    "            percentile = percentiles(base_confs[name], [100 - perc])[0, 0]\n",
    "            base_err.append(compute_error(batch[\"lidar\"], batch[\"gt\"], base_confs[name] >= percentile))\n",
    "        errs[name].append(base_err)\n",
    "        \n",
    "lines = []\n",
    "for key in errs:\n",
    "    lines.append([key, *map(lambda x: x.item(), torch.tensor(errs[key]).mean(axis=0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "christian-scenario",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.title(\"RMSE progressively removing points with the worst confidence\")\n",
    "plt.gca().set_xlim(left=101, right=19)\n",
    "plt.gca().set_xlabel(\"percentile (%)\")\n",
    "plt.gca().set_ylabel(\"error (m)\")\n",
    "\n",
    "for line in lines:\n",
    "    plt.plot(thresholds, line[1:], label=line[0], markersize=10, marker=\".\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifty-eagle",
   "metadata": {},
   "source": [
    "And finally below an image of the points removed by our method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vulnerable-black",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_iter = iter(dl_split_142)\n",
    "for i in range(1):\n",
    "    batch = next(dl_iter)\n",
    "    \n",
    "def depth_imshow(depth):\n",
    "    depth = depth.clone()\n",
    "    depth[depth > 0] = depth.max() - depth[depth > 0]\n",
    "    plt.imshow(depth, cmap=\"inferno\")\n",
    "\n",
    "def normalize(img):\n",
    "    return (img - img.min()) / (img.max() - img.min())\n",
    "    \n",
    "mask = batch[\"lidar\"] > 0\n",
    "with torch.no_grad():\n",
    "    std = model(torch.cat([batch[\"img\"].to(\"cuda\"), batch[\"lidar\"].to(\"cuda\")], 1)).cpu()\n",
    "    percentile = percentiles(std[mask], [85])[0, 0]\n",
    "    mask_ = mask & (std <= percentile)\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.subplot(3, 1, 1); plt.title(\"image\"); plt.imshow(normalize(batch[\"img\"])[0].permute(1, 2, 0))\n",
    "plt.subplot(3, 1, 2); plt.title(\"lidar points\"); depth_imshow(batch[\"lidar\"][0, 0])\n",
    "plt.subplot(3, 1, 3); plt.title(\"lidar filtered\"); depth_imshow(torch.where(\n",
    "    mask_, batch[\"lidar\"], torch.tensor(0.)\n",
    ")[0, 0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1588cf98-47bc-440f-b291-1f0cfeb5a956",
   "metadata": {},
   "source": [
    "## Comparison with [A Surface Geometry Model for LiDAR Depth Completion](https://arxiv.org/pdf/2104.08466.pdf)\n",
    "\n",
    "This paper provides a way to compute a binary mask to remove outliers thus AUC based metrics are not useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02989b6-1741-46ed-a7e6-af4ec10b261b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_error(lidar, gt, conf_mask, depth_mask=None):\n",
    "    \n",
    "    if depth_mask is None:\n",
    "        mask = (lidar > 0) & (gt > 0)\n",
    "    else:\n",
    "        mask = depth_mask\n",
    "        \n",
    "    lidar_, gt_ = lidar[mask][conf_mask], gt[mask][conf_mask]\n",
    "    err = torch.sqrt(torch.mean(torch.square(lidar_ - gt_)))\n",
    "    return err\n",
    "\n",
    "# prepare data\n",
    "\n",
    "def transform(d):\n",
    "    for k in d:\n",
    "        d[k] = F.to_tensor(d[k])\n",
    "    d[\"img\"] = F.normalize(d[\"img\"], mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    return d\n",
    "\n",
    "class DatasetWithMasks(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, split):\n",
    "        self.ds = Dataset(\"../data/dataset\", split=split)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "    \n",
    "    def __getitem__(self, x):\n",
    "        batch = self.ds[x]\n",
    "        \n",
    "        idx = str(x).zfill(10)\n",
    "        batch[\"baseline_mask\"] = np.array(\n",
    "            Image.open(Path(f\"../experiments/baselines/surface_geometry_model/{split}_masks/{idx}.png\"))\n",
    "        )[..., None]\n",
    "        batch[\"baseline_mask\"] = batch[\"baseline_mask\"] / 256\n",
    "        batch[\"baseline_mask\"] = batch[\"baseline_mask\"].astype(bool)\n",
    "        \n",
    "        return transform(batch)\n",
    "    \n",
    "for split in [\"test_1\", \"test_2\"]:\n",
    "    print(f\"\\n== on {split} == \")\n",
    "    ds = DatasetWithMasks(split)\n",
    "    dl = DataLoader(ds)\n",
    "\n",
    "    # compute the error\n",
    "    error_100 = []\n",
    "    error_filtered = []\n",
    "    removed_perc = []\n",
    "    for batch in dl:\n",
    "        mask = (batch[\"lidar\"] > 0) & (batch[\"gt\"] > 0)\n",
    "        error_100.append(torch.sqrt(torch.mean(torch.square(batch[\"lidar\"][mask] - batch[\"gt\"][mask]))))\n",
    "\n",
    "        orig_mask_num = mask.sum()\n",
    "        mask = mask & batch[\"baseline_mask\"]\n",
    "        filtered_mask_num = mask.sum()\n",
    "        removed_perc.append(filtered_mask_num / orig_mask_num)\n",
    "\n",
    "        error_filtered.append(torch.sqrt(torch.mean(torch.square(batch[\"lidar\"][mask] - batch[\"gt\"][mask]))))\n",
    "\n",
    "    error_100 = torch.stack(error_100).mean().item()\n",
    "    error_filtered = torch.stack(error_filtered).mean().item()\n",
    "    removed_perc = 100 - torch.stack(removed_perc).mean().item() * 100\n",
    "    print(\"Error before filtering: {:3.5f} m\".format(error_100))\n",
    "    print(\"Error after filtering:  {:3.5f} m\".format(error_filtered))\n",
    "    print(\"% of removed measures:  {:3.5f} %\".format(removed_perc))\n",
    "\n",
    "    error = []\n",
    "    for batch in dl:\n",
    "        mask = (batch[\"lidar\"] > 0) & (batch[\"gt\"] > 0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            std = model(torch.cat([batch[\"img\"].to(\"cuda\"), batch[\"lidar\"].to(\"cuda\")], 1)).cpu()[mask]\n",
    "\n",
    "        percentile = percentiles(std, [100 - removed_perc])[0, 0]\n",
    "        error.append(compute_error(batch[\"lidar\"], batch[\"gt\"], std <= percentile))\n",
    "\n",
    "    error = torch.stack(error).mean().item()\n",
    "    print(\"\\nOur error removing {:3.5f} %: {:3.5f} m\".format(removed_perc, error))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
